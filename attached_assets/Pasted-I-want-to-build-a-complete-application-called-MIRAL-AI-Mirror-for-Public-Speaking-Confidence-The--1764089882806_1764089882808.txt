I want to build a complete application called MIRAL â€“ AI Mirror for Public Speaking Confidence.
The system will help users practice speeches and presentations using real-time AI feedback.
We are starting from scratch, so please understand the full scope before generating anything.

ğŸŒŸ PROJECT OVERVIEW
MIRAL is an AI-powered virtual mirror that uses the webcam to analyze:


Eye contact


Facial expressions


Posture & body language


Emotions


Voice tone, speed, confidence, filler words


Clarity and structure of speech


It acts like a smart â€œpractice partnerâ€ for interviews, presentations, meetings, debates, and public speaking.
At the end of the session, the app generates a detailed performance report.

ğŸ¯ CORE FEATURES WE WANT
1. Real-time video analysis


Face detection


Eye-contact tracking


Posture correctness


Body movement patterns


Emotion detection (happy, nervous, confident, neutral)


2. Real-time audio analysis


Speech-to-text


Filler words counter


Voice tone & pace


Energy level


3. On-screen feedback during practice


â€œMaintain eye contactâ€


â€œSpeak a little slowerâ€


â€œTry smilingâ€


â€œImprove postureâ€


4. Final performance report
Must include:


Confidence score


Eye contact percentage


Emotion timeline


Pace (WPM)


Filler words graph


Transcript


Strengths & weaknesses


Tips for improvement


Comparison with previous sessions


5. User dashboard


History of sessions


Progress tracking


Scores over time



ğŸ§  TECHNOLOGY STACK (Suggested but flexible)
Backend


FastAPI (Python)


OpenCV (for video)


A face detection model (NOT Mediapipe, because it is problematic on Windows)


An emotion recognition model


Whisper / SpeechRecognition for audio


Numpy, Pydantic


Any simple ML models for posture detection


Frontend
Choose one:


React


Next.js


Flutter Web


Should include webcam recording and real-time display of metrics.
Database


MongoDB or PostgreSQL



ğŸ“Œ API Endpoints Required
POST /analyze-video-frame
POST /analyze-audio
POST /save-session
GET /session/{id}
GET /user-progress


ğŸ”§ EXPECTED OUTPUTS FROM YOU (THE AI TOOL)
Please generate:
1. Full project architecture
Backend + frontend folder structure
API routing structure
Model flow
How video & audio processing will happen
2. Backend code (FastAPI)


Working starter code


Real-time video processing endpoint


Audio processing endpoint


Report generation logic


Session storage logic


3. ML / CV logic


How to detect eye contact


How to detect posture


How to score confidence


How to detect emotions


How to score the user


4. Frontend structure


Webcam capture


Real-time indicators


Final report screen UI


Dashboard UI


5. Database schema


User model


Session model


Reports model


Analytics model


6. Setup instructions
Installation guide
Dependencies
How to run backend
How to run frontend

ğŸ“£ IMPORTANT
We are building this from zero.
Assume no code exists yet.
Create everything from scratch in the most efficient and scalable way.

ğŸ GOAL
By the end, I want a complete working blueprint + starter code + instructions to turn MIRAL into a production-ready AI mirror that improves peopleâ€™s public speaking skills.

If you'd like, I can also generate:
âœ… A README.md for GitHub
âœ… A launch plan
âœ… A UI design prompt
Just tell me!